# Generative Adversarial Network for CIFAR-10

This project demonstrates the implementation of a Generative Adversarial Network (GAN) to generate images similar to those in the CIFAR-10 dataset. The network is built using Keras with a TensorFlow backend.

## Project Overview

The goal of this project is to train a generative model that can create realistic-looking 32x32 pixel color images of objects from the 10 classes in the CIFAR-10 dataset. This is achieved by setting up a GAN, which consists of two neural networks—a Generator and a Discriminator—that are trained simultaneously in a competitive process.

## Dataset

The project utilizes the **CIFAR-10 dataset**, which is a widely used benchmark dataset in computer vision. It consists of 60,000 32x32 color images in 10 classes, with 6,000 images per class. The classes include:

-   Airplane
-   Automobile
-   Bird
-   Cat
-   Deer
-   Dog
-   Frog
-   Horse
-   Ship
-   Truck

The dataset is loaded directly from the `keras.datasets` library.

## Methodology

The GAN architecture is composed of two main components: a Discriminator and a Generator.

### 1. Discriminator

The Discriminator is a convolutional neural network (CNN) designed to distinguish between real images (from the CIFAR-10 dataset) and fake images (created by the Generator). Its architecture is as follows:

-   **Conv2D Layer**: 64 filters, 3x3 kernel, LeakyReLU activation.
-   **Conv2D Layer**: 128 filters, 3x3 kernel, strides of (2,2), LeakyReLU activation.
-   **Conv2D Layer**: 128 filters, 3x3 kernel, strides of (2,2), LeakyReLU activation.
-   **Conv2D Layer**: 256 filters, 3x3 kernel, strides of (2,2), LeakyReLU activation.
-   **Flatten Layer**: To convert the feature maps into a single vector.
-   **Dropout Layer**: For regularization.
-   **Dense Layer**: A single output neuron with a sigmoid activation function to produce a probability score (real or fake).

### 2. Generator

The Generator's role is to create synthetic images that are convincing enough to fool the Discriminator. It takes a random noise vector (from a latent space) as input and upsamples it to produce a 32x32x3 image. The architecture includes:

-   **Dense Layer**: To project the latent space vector into a higher-dimensional space.
-   **Reshape Layer**: To convert the vector into a 4x4 feature map.
-   **Conv2DTranspose Layers**: A series of upsampling layers with 4x4 kernels and strides of (2,2) to progressively increase the image resolution from 4x4 to 32x32.
-   **Conv2D Layer**: The final layer with a `tanh` activation function to produce the output image with pixel values in the range [-1, 1].

## Training

The GAN is trained by alternating between training the Discriminator and the Generator:

1.  **Train the Discriminator**:
    -   A batch of real images from the CIFAR-10 dataset is fed to the Discriminator with a "real" label (1).
    -   A batch of fake images is generated by the Generator and fed to the Discriminator with a "fake" label (0).
    -   The Discriminator's weights are updated based on its ability to correctly classify both real and fake images.

2.  **Train the Generator**:
    -   The Generator's weights are updated by trying to generate images that the Discriminator classifies as "real." During this phase, the Discriminator's weights are frozen.

This process is repeated for 100 epochs, with performance summaries and generated image samples saved every 10 epochs.

## How to Use

1.  **Clone the repository**:
    ```bash
    git clone [https://github.com/savitra-roy/GANs.git](https://github.com/savitra-roy/GANs.git)
    ```
2.  **Install the required libraries**:
    ```bash
    pip install -r requirements.txt
    ```
3.  **Run the Jupyter Notebook** `GANs.ipynb` to start the training process. The notebook will save the generated images and the trained generator model at regular intervals.

## Results

After 100 epochs of training, the model achieved the following performance:

-   **Discriminator Accuracy on Real Images:** ~90%
-   **Discriminator Accuracy on Fake Images:** ~100%

The Generator is capable of producing recognizable, albeit blurry, images of objects. Below is an example of the generated images after 100 epochs.

![Generated Images at Epoch 100](https://raw.githubusercontent.com/savitra-roy/GANs/main/generated_plot_e100.png)

## Conclusion

This project successfully demonstrates the implementation of a DCGAN for generating small color images. The quality of the generated images can be further improved by training for more epochs, tuning hyperparameters, or using more advanced GAN architectures.
